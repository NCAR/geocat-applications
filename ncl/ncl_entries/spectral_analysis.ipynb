{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectral Analysis\n",
    "\n",
    "This example demonstrates how to perform spectral and cross-spectral analysis using the `scipy.signal` module. To learn more about the functions and keyword arguments available in this package, read SciPy's [signal processing documentation](https://docs.scipy.org/doc/scipy/reference/signal.html).\n",
    "\n",
    "The motivation for this example is to demonstrate how to perform the spectral analysis suite of NCL functions: [`specx_anal()`](https://www.ncl.ucar.edu/Document/Functions/Built-in/specx_anal.shtml) and [`specxy_anal()`](https://www.ncl.ucar.edu/Document/Functions/Built-in/specxy_anal.shtml), which calculate the spectra of a series, in Python.\n",
    "\n",
    "This notebook will cover:\n",
    "\n",
    "1. Periodograms\n",
    "1. Smoothing\n",
    "1. Cross Spectral Analysis (cospectrum, quadtrature, phase, coherence squared)\n",
    "1. Coherence\n",
    "\n",
    "For more examples of use, look at [NCL spectral analysis applications](https://www.ncl.ucar.edu/Applications/spec.shtml).\n",
    "\n",
    "To see a concise example using Python, visit the [spectral_analysis](`../../applications/data_analysis/spectral_analysis.ipynb`) notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral Analysis (Periodograms)\n",
    "\n",
    "According to the [NCL `specx_anal()` documentation](https://www.ncl.ucar.edu/Document/Functions/Built-in/specx_anal.shtml), the function:\n",
    "\n",
    "1. Optionally detrends the series\n",
    "2. Optionally tapers the series\n",
    "3. Calculates the variance of the detrended/tapered series\n",
    "4. Finds the Fast Fourier Transform of the series\n",
    "5. Squares the Fourier coefficients (i.e. the periodogram)\n",
    "6. Smooths the periodogram estimates \n",
    "7. Normalizes the periodogram so that the area under the curve matches the calculated variance\n",
    "\n",
    "We will be able to combine steps 4 and 5 using `scipy.signal.periodogram()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import geocat.datafiles as gcd\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Data\n",
    "\n",
    "We'll use the [`geocat-datafiles`](https://github.com/NCAR/geocat-datafiles) module to access the relevant datafile for this example: `SOI_Darwin.nc`\n",
    "\n",
    "Then, we use [`xarray.open_dataset()`](http://xarray.pydata.org/en/stable/generated/xarray.open_dataset.html) function to read the data as an xarray dataset.\n",
    "\n",
    "This data represents the Darwin Southern Oscillation Index between 1882 and 1998 using normalized sea level pressure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soi_darwin = xr.open_dataset(gcd.get('netcdf_files/SOI_Darwin.nc'))\n",
    "\n",
    "soi_darwin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series Correction\n",
    "\n",
    "Currently, our `time` coordinate is in units of months since January 1882, we'll use `pandas` to change this to the conventional `DatetimeIndex`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = pd.Timestamp('1882-01-01')\n",
    "dates = [\n",
    "    start_date + pd.DateOffset(months=int(month))\n",
    "    for month in soi_darwin.indexes['time']\n",
    "]\n",
    "datetime_index = pd.DatetimeIndex(dates)\n",
    "\n",
    "datetime_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soi = soi_darwin.DSOI\n",
    "soi['time'] = datetime_index\n",
    "\n",
    "soi.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detrend\n",
    "\n",
    "Here we will do a simple detrending by removing the mean with [`scipy.signal.detrend()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.detrend.html).\n",
    "\n",
    "If you wanted to perform a linear least-squares fit, change `type='linear'`.\n",
    "\n",
    "The `scipy.signal.periodogram()` function does have a detrending option, but because we are using an unsupported tapering window, and because detrending must be done before tapering, here we demonstrate how to separate out these steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soi_detrended = scipy.signal.detrend(soi, type='constant')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tapering\n",
    "\n",
    "According to the code in [NCL's `specx_dp.DTAPERX`](https://github.com/NCAR/ncl/blob/develop/ni/src/lib/nfpfort/specx_dp.f#L702), the tapering performed in the NCL example is split-cosine-bell tapering.\n",
    "\n",
    "Split-cosine-bell tapering is sometimes identified to as Tukey tapering, however Tukey can also refer to \"cosine tapering\".\n",
    "\n",
    "Here we demonstrate how to perform a unique tapering window with [`scipy.signal.windows.tukey`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.windows.tukey.html). Your desired tapering can be chosen instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_taper = 0.1\n",
    "tukey_window = scipy.signal.windows.tukey(\n",
    "    len(soi_detrended), alpha=percent_taper, sym=False\n",
    ")  # generates a periodic window\n",
    "\n",
    "soi_tapered = soi_detrended * tukey_window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Periodogram\n",
    "\n",
    "Now we can call [`scipy.signal.periodogram()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.periodogram.html).\n",
    "\n",
    "A periodogram estimate is the square of the coefficients from the Fourier transform\n",
    "\n",
    "There is also a `scaling` keyword that defaults to `density` for computing the power spectral density with units of {math}`V^{2}/Hz`, with V being the units of the input array (here dimensionless), and `Hz` representing your frequency units (we'll use per month instead of per second). `spectral` is also supported and produces the squared magnitude spectrum with units of {math}`V^{2}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_soi, psd_soi = scipy.signal.periodogram(\n",
    "    soi_tapered,\n",
    "    fs=1,  # sample monthly\n",
    "    detrend=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothing\n",
    "\n",
    "To provide statistical reliability, the periodogram estimates **must be smoothed**.\n",
    "\n",
    "The NCL example uses modified Daniel kernel smoothing, which is not supported, here we'll demonstrate how to perform your own custom smoothing using [`scipy.signal.convolve()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.convolve.html).\n",
    "\n",
    "Here is a [list of supported smoothing windows](https://docs.scipy.org/doc/scipy/reference/signal.windows.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 7  # define smoothing constant\n",
    "\n",
    "kernel = np.ones(7)  # Create a Daniel smoothing kernel\n",
    "kernel[0] = (\n",
    "    0.5  # \"Modify\" kernel by making the endpoints have half the weight of the interior points\n",
    ")\n",
    "kernel[-1] = 0.5\n",
    "kernel = kernel / kernel.sum()\n",
    "\n",
    "smoothed_psd = scipy.signal.convolve(\n",
    "    psd_soi, kernel, mode='same'\n",
    ")  # Sets output array as the same length as the first input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "\n",
    "Lastly we'll normalize our smoothed periodogram by the variance of the detrended and tapered series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance = np.var(soi_tapered, ddof=1)\n",
    "\n",
    "df = freq_soi[1] - freq_soi[0]  # Frequency step\n",
    "\n",
    "# Create an array to adjust contributions of endpoints\n",
    "frac = np.ones_like(freq_soi)\n",
    "frac[0] = 0.5\n",
    "frac[-1] = 0.5\n",
    "\n",
    "current_area = np.sum(\n",
    "    smoothed_psd * df * frac\n",
    ")  # Calculate the current area under the curve\n",
    "normalization_factor = variance / current_area  # Find the factor to adjust this area\n",
    "\n",
    "normalized_psd = (\n",
    "    smoothed_psd * normalization_factor\n",
    ")  # Apply the normalization factor to the smoothed power spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(freq_soi, normalized_psd)\n",
    "plt.xlabel('Frequency (Cycles / Month)')\n",
    "plt.ylabel('Variance (Pressure$^2$ / Frequency)')\n",
    "plt.title('Darwin Southern Oscillation Index (1882 - 1998) - Power Spectral Density')\n",
    "plt.xlim([0, 0.5]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Spectral Analysis\n",
    "\n",
    "### Read in Data\n",
    "\n",
    "For our cross-spectral data we'll look at `SLP_DarwinTahitiAnom` which contains Darwin and Tahiti sea level pressure anomalies between 1935-1998.\n",
    "\n",
    "This data will need a time index correction to use the standard `DateTimeIndex`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slp_darwin = xr.open_dataset(gcd.get('netcdf_files/SLP_DarwinTahitiAnom.nc'))\n",
    "\n",
    "# Time Series Correction\n",
    "start_date = pd.Timestamp('1935-01-01')  # Months Since January 1935\n",
    "dates = [\n",
    "    start_date + pd.DateOffset(months=int(month))\n",
    "    for month in slp_darwin.indexes['time']\n",
    "]\n",
    "datetime_index = pd.DatetimeIndex(dates)\n",
    "\n",
    "slp_darwin['time'] = datetime_index\n",
    "slp_darwin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dslp = slp_darwin.DSLP  # Darwin\n",
    "dslp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tslp = slp_darwin.TSLP  # Tahiti\n",
    "tslp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dslp.plot(label='Darwin')\n",
    "tslp.plot(label='Tahiti')\n",
    "plt.legend()\n",
    "plt.ylabel('Sea Level Pressure Anomalies [hPa]');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Power Spectral Density\n",
    "\n",
    "We will calculate cospectrum, quadtrature, and phase by leveraging [`scipy.signal.csd()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.csd.html) and computing its real (cospectrum) and imaginary (quadtrature) components, and calculating the angle between them (phase)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, pxy = scipy.signal.csd(\n",
    "    dslp,\n",
    "    tslp,\n",
    "    fs=1,  # monthly\n",
    "    detrend='constant',\n",
    ")  # remove mean\n",
    "\n",
    "cospectrum = np.real(pxy)\n",
    "quadrature = np.imag(pxy)\n",
    "\n",
    "phase = np.angle(pxy, deg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(10, 5))\n",
    "\n",
    "axs[0].plot(f, cospectrum)\n",
    "axs[0].set_xlim([0, 0.5])\n",
    "axs[0].set_xlabel('Frequency (Cycles / Month)')\n",
    "axs[0].set_ylabel('Cospectrum')\n",
    "\n",
    "axs[1].plot(f, quadrature)\n",
    "axs[1].set_xlim([0, 0.5])\n",
    "axs[1].set_ylim([-3, 3])\n",
    "axs[1].set_xlabel('Frequency (Cycles / Month)')\n",
    "axs[1].set_ylabel('Quadrature')\n",
    "\n",
    "axs[2].plot(f, phase)\n",
    "axs[2].set_xlim([0, 0.5])\n",
    "axs[2].set_ylim([-200, 200])\n",
    "axs[2].set_xlabel('Frequency (Cycles / Month)')\n",
    "axs[2].set_ylabel('Phase')\n",
    "\n",
    "fig.suptitle(\n",
    "    'Darwin and Tahiti Sea Level Pressure Anomalies (1935-1998) - Cross-Spectral Analysis'\n",
    ")\n",
    "\n",
    "plt.tight_layout();  # Makes the plots y-labels not overlap the neighboring plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coherence Squared\n",
    "\n",
    "Coherence is a measure of how similar two specta are, with regards to their frequency and phase offset relative to one another. \n",
    "\n",
    "For coherence squared, simply square the output from [`scipy.signal.coherence()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.coherence.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, cxy = scipy.signal.coherence(\n",
    "    dslp,\n",
    "    tslp,\n",
    "    fs=1,  # monthly\n",
    "    detrend='constant',\n",
    ")  # remove mean\n",
    "\n",
    "co_sq = cxy**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(f, co_sq)\n",
    "plt.xlim([0, 0.5])\n",
    "plt.ylim([0, 1])\n",
    "plt.xlabel('Frequency (Cycles / Month)')\n",
    "plt.ylabel('Coherence SQ')\n",
    "\n",
    "plt.title('Darwin and Tahiti Sea Level Pressure Anomalies (1935-1998)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peridogram and Smoothing\n",
    "\n",
    "Previously we demonstrated additional tapering and normalization steps for the periodgram. Now we demonstrate a faster working example for our Darwin and Tahiti datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Periodogram\n",
    "freq_dslp, dslp_psd = scipy.signal.periodogram(\n",
    "    dslp,\n",
    "    fs=1,  # monthly\n",
    "    detrend='constant',\n",
    ")  # remove mean\n",
    "freq_tslp, tslp_psd = scipy.signal.periodogram(tslp, fs=1, detrend='constant')\n",
    "\n",
    "\n",
    "# Perform modified Daniel Smoothing\n",
    "k = 3  # smoothing constant\n",
    "\n",
    "window = scipy.signal.windows.hann(2 * k + 1)  # Hann Window\n",
    "window = window / window.sum()  # Normalize window\n",
    "\n",
    "dslp_smoothed = scipy.signal.convolve(dslp_psd, window, mode='same')\n",
    "tslp_smoothed = scipy.signal.convolve(tslp_psd, window, mode='same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "axs[0].plot(freq_dslp, dslp_smoothed)\n",
    "axs[0].set_xlim([0, 0.5])\n",
    "axs[0].set_ylim([0, 30])\n",
    "axs[0].set_xlabel('Frequency (cycles/month)')\n",
    "axs[0].set_ylabel('Variance of Darwin SLP')\n",
    "\n",
    "axs[1].plot(freq_tslp, tslp_smoothed)\n",
    "axs[1].set_xlim([0, 0.5])\n",
    "axs[1].set_ylim([0, 30])\n",
    "axs[1].set_xlabel('Frequency (cycles/month)')\n",
    "axs[1].set_ylabel('Variance of Tahiti SLP')\n",
    "\n",
    "fig.suptitle(\n",
    "    'Darwin and Tahiti Sea Level Pressure (SLP) Anomalies (1935-1998) - Power Spectral Density'\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curious about how to more closely replicate the NCL version of spectral analysis? Check out our ['NCL Spectral Analysis Notebook']('../../ncl/NCL_spectral_analysis.ipynb')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
